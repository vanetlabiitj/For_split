{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37582b5-403f-4a80-8184-93ea8d75658b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jayant\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d8b64d-c094-469a-ac47-6d55fe203cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7bc66a-3048-41d3-a897-e80686884ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_images.reshape((60000, 784))\n",
    "x_test = test_images.reshape((10000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bad98c9-cdbb-4795-9d12-b2d56de3ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test  = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ed1f2d-daa5-4a45-a1e3-1247dfe52acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(train_labels, dtype =\"uint8\")\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, dtype =\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca9d2ef-29b9-4937-bb99-3cb79ff154cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1ad330-cbde-440a-8797-117dd0db21c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50cdb84e-cafc-457c-a74f-e7da26f66dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79310ae-3a7b-4e6e-afd7-6e2a61c1dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    \"\"\"Computes softmax function.\n",
    "\n",
    "    z: array of input values.\n",
    "\n",
    "    Returns an array of outputs with the same shape as z.\"\"\"\n",
    "    # For numerical stability: make the maximum of z's to be 0.\n",
    "    cache = Z\n",
    "    shiftz = Z - np.max(Z)\n",
    "    exps = np.exp(shiftz)\n",
    "    A = exps / np.sum(exps)\n",
    "    return A,cache\n",
    "\n",
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f08a92-7bdd-49b5-9cd9-0585be985b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = W.dot(A) + b\n",
    "    #print(\"Shapes\",Z.shape, A.shape, W.shape, b.shape )\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c81db8-98dc-446b-a1bb-be5dfccf16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    if activation == \"softmax\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "   \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21fe43f4-02d8-4eab-8c59-bde6d1ea458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_CE(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, (number of classes,batch_size)\n",
    "    Y -- true \"label\" vector (number of classes, batch_size)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "#     print(\"shape of y_hat\",AL.shape )\n",
    "#     print(\"shape of y\",Y.shape )\n",
    "    \n",
    "    m = AL.shape[1]\n",
    "    # Compute loss from aL and y.\n",
    "    cost = (1./m) * np.sum((-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T)))\n",
    "#     print(\"Cost shape: \", cost.shape)\n",
    "\n",
    "    \n",
    "    cost = np.squeeze(cost)# To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    \n",
    "#     print(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def compute_cost_categorical_CE(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, (number of classes,batch_size)\n",
    "    Y -- true \"label\" vector (number of classes, batch_size)\n",
    "\n",
    "    Returns:\n",
    "    cost -- Categorical_cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "#     print(\"shape of y_hat\",AL.shape )\n",
    "#     print(\"shape of y\",Y.shape )\n",
    "    \n",
    "    m = AL.shape[1]\n",
    "    # Compute loss from aL and y.\n",
    "    cost = - (1./m) * np.sum(np.multiply(Y,np.log(AL)))\n",
    "#     print(\"Cost shape: \", cost.shape)\n",
    "\n",
    "    \n",
    "    cost = np.squeeze(cost)# To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    \n",
    "#     print(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae76d310-de34-491f-856f-98742bae97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax_backward wont handle the batch as of now\n",
    "def softmax_backward(dA, cache):\n",
    "    \"\"\"Computes the gradient of the softmax function.\n",
    "\n",
    "    z: (T, 1) array of input values where the gradient is computed. T is the\n",
    "       number of output classes.\n",
    "\n",
    "    Returns D (T, T) the Jacobian matrix of softmax(z) at the given z. D[i, j]\n",
    "    is DjSi - the partial derivative of Si w.r.t. input j.\n",
    "    \"\"\"\n",
    "    z = cache\n",
    "    Sz, _ = softmax(z)\n",
    "#     print(\"DA Shape \", dA.shape)\n",
    "#     print(\"Sz Shape \", Sz.shape)\n",
    "    \n",
    "    # -SjSi can be computed using an outer product between Sz and itself. Then\n",
    "    # we add back Si for the i=j cases by adding a diagonal matrix with the\n",
    "    # values of Si on its diagonal.\n",
    "   \n",
    "    D = -np.outer(Sz, Sz) + np.diag(Sz.flatten())\n",
    "    return D.dot(dA)\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    \n",
    "    print(dA.shape,Z.shape)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1416f202-6b01-40cd-85dc-d02fde23d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "        \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    elif activation == \"softmax\":\n",
    "        dZ = softmax_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aebf7caf-e5b6-411f-9cc9-9766ab5dec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SOFTMAX computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"softmax\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (10,X.shape[1]))\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "875126a5-76eb-4d0f-a4fb-21781a941895",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= x_train.T\n",
    "Y=train_labels.T\n",
    "learning_rate = 0.0075\n",
    "num_iterations = 100\n",
    "print_cost=False\n",
    "\n",
    "cost = 0\n",
    "\n",
    "np.random.seed(1)\n",
    "grads = {}\n",
    "costs = []                              # to keep track of the cost\n",
    "m = X.shape[1]                           # number of examples\n",
    "(n_x, n_h, n_y) = (784,20,10)\n",
    "costs_batch = []                             # to keep track of the cost\n",
    "costs_iterations = []\n",
    "grads['dW1'] = 0\n",
    "grads['db1'] = 0\n",
    "grads['dW2'] = 0\n",
    "grads['db2'] = 0\n",
    "iteration = 0\n",
    "\n",
    "# Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "W1 = parameters[\"W1\"]\n",
    "b1 = parameters[\"b1\"]\n",
    "W2 = parameters[\"W2\"]\n",
    "b2 = parameters[\"b2\"]\n",
    "\n",
    "CACHE1 = []\n",
    "CACHE2 = []\n",
    "A1STORE = []\n",
    "A2STORE = []\n",
    "dA1STORE = []\n",
    "dA2STORE = []\n",
    "# Loop (gradient descent)\n",
    "\n",
    "temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96c13843-60ef-4dd3-a296-d1ac2bac8a33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'msg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      2\u001b[0m myint \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sys\u001b[38;5;241m.\u001b[39mgetsizeof(\u001b[43mmsg\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'msg' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "myint = 12\n",
    "print(sys.getsizeof(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46961895-9af0-4e1c-84f2-cc1b422c1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import socket\n",
    "import struct\n",
    "\n",
    "HOST = \"10.6.1.155\" #ip address\n",
    "device_id = 9001 #port Number\n",
    "\n",
    "def send_data(device_id,msg):\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.connect((HOST, device_id))\n",
    "        s.sendall(msg)\n",
    "        \n",
    "def recive_data(device_id):\n",
    "    print(f\"{device_id} read to recive data\")\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind((HOST, device_id))\n",
    "        s.listen()\n",
    "        conn, addr = s.accept()\n",
    "        with conn:\n",
    "            print(f\"Connected by {addr} \\n\")\n",
    "            while True:\n",
    "                data = conn.recv(1024)\n",
    "                print(data)\n",
    "                if not data:\n",
    "                    break\n",
    "    print(f'recived data at {device_id} \\n')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72dc0b6e-95a3-485e-ae7a-6501eb8c3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, cache = linear_activation_forward(np.reshape(X[:,0], (784,1)), W1, b1, activation=\"relu\")\n",
    "layer_data = { 'A' : A,\n",
    "               'cache' : cache }\n",
    "device_message = {\"Source\":\"edge_1\",\"target\":\"edge_2\",\"type\":\"forward\",\"Data\": layer_data }\n",
    "msg = pickle.dumps(device_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f2e197e-afbb-4b41-b011-e315afa1f9f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] No connection could be made because the target machine actively refused it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_devices:\n\u001b[0;32m      5\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43msend_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msend_to_devices\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     recive_data(device_id)\n",
      "Cell \u001b[1;32mIn[23], line 10\u001b[0m, in \u001b[0;36msend_data\u001b[1;34m(device_id, msg)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_data\u001b[39m(device_id,msg):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m socket\u001b[38;5;241m.\u001b[39msocket(socket\u001b[38;5;241m.\u001b[39mAF_INET, socket\u001b[38;5;241m.\u001b[39mSOCK_STREAM) \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[1;32m---> 10\u001b[0m         \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHOST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m         s\u001b[38;5;241m.\u001b[39msendall(msg)\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it"
     ]
    }
   ],
   "source": [
    "first_devices = True \n",
    "send_to_devices = 9002\n",
    "if __name__ ==\"__main__\":\n",
    "    if first_devices:\n",
    "        time.sleep(2)\n",
    "        send_data(send_to_devices,msg)\n",
    "    else:\n",
    "        recive_data(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77d50c28-721b-445c-bdd0-e781449781b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_model_pipeline(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 100, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a two-layer neural network: LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (n_x, number of examples)\n",
    "    Y -- true \"label\" vector , of shape (10, number of examples)\n",
    "    layers_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- If set to True, this will print the cost every 100 iterations \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary containing W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    cost = 0\n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost\n",
    "    m = X.shape[1]                           # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    costs_batch = []                             # to keep track of the cost\n",
    "    costs_iterations = []\n",
    "    grads['dW1'] = 0\n",
    "    grads['db1'] = 0\n",
    "    grads['dW2'] = 0\n",
    "    grads['db2'] = 0\n",
    "    iteration = 0\n",
    "    \n",
    "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    CACHE1 = []\n",
    "    CACHE2 = []\n",
    "    A1STORE = []\n",
    "    A2STORE = []\n",
    "    dA1STORE = []\n",
    "    dA2STORE = []\n",
    "    # Loop (gradient descent)\n",
    "    \n",
    "    temp = []\n",
    "    for k in range(num_iterations):\n",
    "        temp = temp + list(np.random.permutation(60000).astype(int)) \n",
    "    \n",
    "    \n",
    "    for tstep in range(num_iterations*60000):\n",
    "        \n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1, W2, b2\". Output: \"A1, cache1, A2, cache2\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A1, cache1 = linear_activation_forward(np.reshape(X[:,temp[tstep]], (784,1)), W1, b1, activation=\"relu\")\n",
    "        CACHE1 =  CACHE1 + [cache1] \n",
    "        A1STORE = A1STORE + [A1]\n",
    "\n",
    "        if(tstep>=1):\n",
    "            A2, cache2 = linear_activation_forward(A1STORE[0], W2, b2, activation=\"softmax\")\n",
    "            CACHE2 = CACHE2 + [cache2] \n",
    "            A2STORE = A2STORE + [A2]\n",
    "            A1STORE.pop(0)\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            # Compute cost\n",
    "            ### START CODE HERE ### (≈ 1 line of code)\n",
    "            cost = compute_cost_categorical_CE(A2, np.reshape(Y[:,temp[tstep-1]], (10,1)))\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "        if(tstep >= 2):\n",
    "            # Initializing backward propagation\n",
    "\n",
    "            dA2 = - (np.divide(np.reshape(Y[:,temp[tstep-2]], (10,1)), A2STORE[0]))\n",
    "            A2STORE.pop(0)\n",
    "            dA2STORE = dA2STORE + [dA2]\n",
    "\n",
    "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        if(tstep >= 3):    \n",
    "            dA1, dW2, db2 = linear_activation_backward(dA2STORE[0], CACHE2[0], activation=\"softmax\")\n",
    "            CACHE2.pop(0)\n",
    "            dA2STORE.pop(0)\n",
    "            dA1STORE = dA1STORE + [dA1]\n",
    "            grads['dW2'] += dW2\n",
    "            grads['db2'] += db2\n",
    "            if(np.mod(tstep-3, 32)==0):\n",
    "                W2 += -learning_rate*grads['dW2']/32\n",
    "                parameters[\"W2\"] = W2\n",
    "                grads['dW2'] = 0\n",
    "                b2 += -learning_rate*grads['db2']/32\n",
    "                parameters[\"b2\"] = b2\n",
    "                grads['db2'] = 0\n",
    "                \n",
    "        if(tstep >= 4):    \n",
    "            dA0, dW1, db1 = linear_activation_backward(dA1STORE[0], CACHE1[0], activation=\"relu\")\n",
    "            CACHE1.pop(0)\n",
    "            dA1STORE.pop(0)\n",
    "            grads['dW1'] += dW1\n",
    "            grads['db1'] += db1\n",
    "            if(np.mod(tstep-4, 32)==0):\n",
    "                W1 += -learning_rate*grads['dW1']/32\n",
    "                parameters[\"W1\"] = W1\n",
    "                grads['dW1'] = 0\n",
    "                b1 += -learning_rate*grads['db1']/32\n",
    "                parameters[\"b1\"] = b1\n",
    "                grads['db1'] = 0\n",
    "           \n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "#         # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "#         grads['dW1'] += dW1\n",
    "#         grads['db1'] += db1\n",
    "#         grads['dW2'] += dW2\n",
    "#         grads['db2'] += db2\n",
    "\n",
    "        if np.mod(tstep,32) == 0:\n",
    "            costs_batch.append(cost)\n",
    "#             print(\"Cost batch {}: {}\".format(int(tstep/32), np.squeeze(cost)))\n",
    "\n",
    "            costs.append(cost)\n",
    "        \n",
    "\n",
    "#             # Update parameters.\n",
    "#             ### START CODE HERE ### (approx. 1 line of code)\n",
    "#             parameters = update_parameters(parameters, grads, learning_rate/32)\n",
    "#             ### END CODE HERE ###\n",
    "\n",
    "#             # Retrieve W1, b1, W2, b2 from parameters\n",
    "#             W1 = parameters[\"W1\"]\n",
    "#             b1 = parameters[\"b1\"]\n",
    "#             W2 = parameters[\"W2\"]\n",
    "#             b2 = parameters[\"b2\"]\n",
    "\n",
    "#             grads['dW1'] = 0\n",
    "#             grads['db1'] = 0\n",
    "#             grads['dW2'] = 0\n",
    "#             grads['db2'] = 0\n",
    "\n",
    "\n",
    "          \n",
    "        if(np.mod(tstep, 60000)==0):\n",
    "            iteration = iteration + 1\n",
    "            c = sum(costs_batch)/len(costs_batch)\n",
    "\n",
    "\n",
    "            print(\"Cost iteration {}: {}\".format(iteration, np.squeeze(c)))\n",
    "            costs_iterations.append(c)\n",
    "\n",
    "    # plot the cost\n",
    "\n",
    "    plt.plot(np.squeeze(costs_iterations))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "640bf520-30d9-44fd-bf4d-0f067d3de6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost iteration 1: 0.0\n",
      "Cost iteration 2: 1.7959510246293837\n",
      "Cost iteration 3: 1.1995981466348278\n",
      "Cost iteration 4: 0.9466391631174537\n",
      "Cost iteration 5: 0.8061243604714116\n",
      "Cost iteration 6: 0.7166006035756952\n",
      "Cost iteration 7: 0.6467870534759859\n",
      "Cost iteration 8: 0.5960476340371696\n",
      "Cost iteration 9: 0.5550971894624664\n",
      "Cost iteration 10: 0.5279431333294721\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters_two_layer_model = two_layer_model_pipeline(x_train.T, train_labels.T, layers_dims = (n_x, n_h, n_y), num_iterations = 10, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e1ab976-ae0e-479f-89a9-f1f45a6e99be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m(x_train\u001b[38;5;241m.\u001b[39mT, train_labels\u001b[38;5;241m.\u001b[39mT, parameters_two_layer_model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "predict(x_train.T, train_labels.T, parameters_two_layer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5833a27-ff80-4940-a97e-437329503476",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m(x_test\u001b[38;5;241m.\u001b[39mT, test_labels\u001b[38;5;241m.\u001b[39mT, parameters_two_layer_model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "predict(x_test.T, test_labels.T, parameters_two_layer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e512706-100f-4e1d-bc3d-43596aec493d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839dc2c-a58c-40e6-9cad-d9a814e937c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
